{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe2414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 09:18:02,297 INFO Output directory: binary-xgb-study-2\n",
      "2023-05-09 09:18:02,298 WARNING No id column specified. Will default to `id`.\n",
      "2023-05-09 09:18:02,298 INFO Reading training data\n",
      "2023-05-09 09:18:02,355 INFO Mem. usage decreased to 2.64 Mb (29.2% reduction)\n",
      "2023-05-09 09:18:02,368 INFO Problem type: binary_classification\n",
      "2023-05-09 09:18:02,369 INFO Creating folds\n",
      "2023-05-09 09:18:02,396 INFO Encoding target(s)\n",
      "2023-05-09 09:18:02,414 INFO Found 8 categorical features.\n",
      "2023-05-09 09:18:02,414 INFO Encoding categorical features\n",
      "2023-05-09 09:18:02,717 INFO Model config: objective='loss' algo='xgb' fs=1 train_filename='./data_samples/binary_classification.csv' test_filename=None idx='id' targets=['income'] problem_type=<ProblemType.binary_classification: 1> output='binary-xgb-study-2' features=['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country'] num_folds=5 use_gpu=False seed=42 categorical_features=['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country'] num_trials=100 time_limit=360 fast=False\n",
      "2023-05-09 09:18:02,717 INFO Saving model config\n",
      "2023-05-09 09:18:02,719 INFO Saving encoders\n",
      "2023-05-09 09:18:02,726 INFO Feature Importance Step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 09:18:06,104 INFO Feature selection is done, selected features:\n",
      "2023-05-09 09:18:06,105 INFO Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
      "       'marital.status', 'occupation', 'relationship', 'sex', 'capital.gain',\n",
      "       'capital.loss', 'hours.per.week'],\n",
      "      dtype='object')\n",
      "2023-05-09 09:18:06,107 INFO Features updated with selected features\n",
      "2023-05-09 09:18:06,107 INFO Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
      "       'marital.status', 'occupation', 'relationship', 'sex', 'capital.gain',\n",
      "       'capital.loss', 'hours.per.week'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t8 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t0\n",
      "Rejected: \t2\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t0\n",
      "Rejected: \t2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-09 09:18:06,416]\u001b[0m A new study created in RDB with name: autotuna\u001b[0m\n",
      "2023-05-09 09:18:06,421 INFO ======================================================\n",
      "2023-05-09 09:18:06,422 INFO |                                                    |\n",
      "2023-05-09 09:18:06,423 INFO |                                                    |\n",
      "2023-05-09 09:18:06,424 INFO |  Monitor the study                                 |\n",
      "2023-05-09 09:18:06,425 INFO | Run the following command under the output folder: |\n",
      "2023-05-09 09:18:06,426 INFO | cd  binary-xgb-study-2/params.db                                     |\n",
      "2023-05-09 09:18:06,427 INFO | optuna-dashboard sqlite:///params.db               |\n",
      "2023-05-09 09:18:06,428 INFO |                                                    |\n",
      "2023-05-09 09:18:06,429 INFO |                                                    |\n",
      "2023-05-09 09:18:06,430 INFO ======================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:18:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 09:18:34,505 INFO Metrics: {'auc': 0.837883931073075, 'logloss': 0.40768202275637283, 'f1': 0.45357971730714003, 'accuracy': 0.8110007258210852, 'precision': 0.7463978387318436, 'recall': 0.3258500149581821}\n",
      "\u001b[32m[I 2023-05-09 09:18:34,537]\u001b[0m Trial 0 finished with value: 0.40768202275637283 and parameters: {'learning_rate': 0.09283807017743805, 'reg_lambda': 0.8106289104547307, 'reg_alpha': 1.0505087056715205e-08, 'subsample': 0.862625874623844, 'colsample_bytree': 0.973326883528953, 'max_depth': 4, 'early_stopping_rounds': 315, 'n_estimators': 15000, 'tree_method': 'approx', 'booster': 'gblinear'}. Best is trial 0 with value: 0.40768202275637283.\u001b[0m\n",
      "2023-05-09 09:19:42,656 INFO Metrics: {'auc': 0.9233905801841225, 'logloss': 0.2872630467197565, 'f1': 0.7030403284612767, 'accuracy': 0.8687077461029556, 'precision': 0.7718489815312758, 'recall': 0.6457065952576059}\n",
      "\u001b[32m[I 2023-05-09 09:19:42,679]\u001b[0m Trial 1 finished with value: 0.2872630467197565 and parameters: {'learning_rate': 0.04429327752779358, 'reg_lambda': 2.5898583318063295, 'reg_alpha': 5.38222826154189, 'subsample': 0.5266355012244603, 'colsample_bytree': 0.8902287091568296, 'max_depth': 3, 'early_stopping_rounds': 379, 'n_estimators': 7000, 'tree_method': 'approx', 'booster': 'gbtree', 'gamma': 8.453088721175541e-06, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.2872630467197565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:19:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:19:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:19:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:19:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:19:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 09:19:58,587 INFO Metrics: {'auc': 0.8534757856461826, 'logloss': 0.38421284144194134, 'f1': 0.5509471770494441, 'accuracy': 0.8238688282101455, 'precision': 0.7134828603547116, 'recall': 0.44879277714910054}\n",
      "\u001b[32m[I 2023-05-09 09:19:58,604]\u001b[0m Trial 2 finished with value: 0.38421284144194134 and parameters: {'learning_rate': 0.163608784042011, 'reg_lambda': 1.273054734206101e-05, 'reg_alpha': 4.026398963444366e-06, 'subsample': 0.711647226265213, 'colsample_bytree': 0.14315778091045867, 'max_depth': 9, 'early_stopping_rounds': 182, 'n_estimators': 20000, 'tree_method': 'hist', 'booster': 'gblinear'}. Best is trial 1 with value: 0.2872630467197565.\u001b[0m\n",
      "2023-05-09 09:22:05,877 INFO Metrics: {'auc': 0.9261198690920838, 'logloss': 0.2825967756522646, 'f1': 0.7040608594132072, 'accuracy': 0.8697213680746616, 'precision': 0.7769413747185147, 'recall': 0.6437941428961642}\n",
      "\u001b[32m[I 2023-05-09 09:22:05,903]\u001b[0m Trial 3 finished with value: 0.2825967756522646 and parameters: {'learning_rate': 0.01651272856332462, 'reg_lambda': 1.3565381168525197, 'reg_alpha': 2.2014805732105303e-08, 'subsample': 0.46567511903056225, 'colsample_bytree': 0.1339642851802558, 'max_depth': 4, 'early_stopping_rounds': 390, 'n_estimators': 20000, 'tree_method': 'approx', 'booster': 'gbtree', 'gamma': 0.22098503962918958, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.2825967756522646.\u001b[0m\n",
      "2023-05-09 09:24:03,896 INFO Metrics: {'auc': 0.911264164694513, 'logloss': 0.3160680394775544, 'f1': 0.6560139673003264, 'accuracy': 0.8552560631901951, 'precision': 0.7668476102843657, 'recall': 0.5733947594334101}\n",
      "\u001b[32m[I 2023-05-09 09:24:03,916]\u001b[0m Trial 4 finished with value: 0.3160680394775544 and parameters: {'learning_rate': 0.17903531587534469, 'reg_lambda': 2.4984579828889117e-06, 'reg_alpha': 98.76835383356398, 'subsample': 0.3413786828653983, 'colsample_bytree': 0.40486285394249055, 'max_depth': 9, 'early_stopping_rounds': 476, 'n_estimators': 15000, 'tree_method': 'approx', 'booster': 'gbtree', 'gamma': 3.801617408877584e-07, 'grow_policy': 'depthwise'}. Best is trial 3 with value: 0.2825967756522646.\u001b[0m\n",
      "2023-05-09 09:24:49,174 INFO Metrics: {'auc': 0.927756618236908, 'logloss': 0.27931406036069795, 'f1': 0.7102631837172906, 'accuracy': 0.8720860018764209, 'precision': 0.781039520471137, 'recall': 0.6514452530534203}\n",
      "\u001b[32m[I 2023-05-09 09:24:49,194]\u001b[0m Trial 5 finished with value: 0.27931406036069795 and parameters: {'learning_rate': 0.020129391987393767, 'reg_lambda': 0.6784628705213062, 'reg_alpha': 2.5341785848022255e-05, 'subsample': 0.5327688978038144, 'colsample_bytree': 0.7231534295030235, 'max_depth': 6, 'early_stopping_rounds': 488, 'n_estimators': 15000, 'tree_method': 'exact', 'booster': 'gbtree', 'gamma': 8.333808809136198e-06, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 0.27931406036069795.\u001b[0m\n",
      "2023-05-09 09:24:49,203 INFO Best params: {'booster': 'gbtree', 'colsample_bytree': 0.7231534295030235, 'early_stopping_rounds': 488, 'gamma': 8.333808809136198e-06, 'grow_policy': 'lossguide', 'learning_rate': 0.020129391987393767, 'max_depth': 6, 'n_estimators': 15000, 'reg_alpha': 2.5341785848022255e-05, 'reg_lambda': 0.6784628705213062, 'subsample': 0.5327688978038144, 'tree_method': 'exact'}\n",
      "2023-05-09 09:24:49,204 INFO Training complete\n",
      "2023-05-09 09:24:49,205 INFO Creating OOF and test predictions\n",
      "2023-05-09 09:24:49,209 INFO Training and predicting for fold 0\n",
      "2023-05-09 09:24:57,476 INFO Fold 0 done!\n",
      "2023-05-09 09:24:57,477 INFO Training and predicting for fold 1\n",
      "2023-05-09 09:25:06,840 INFO Fold 1 done!\n",
      "2023-05-09 09:25:06,841 INFO Training and predicting for fold 2\n",
      "2023-05-09 09:25:16,278 INFO Fold 2 done!\n",
      "2023-05-09 09:25:16,278 INFO Training and predicting for fold 3\n",
      "2023-05-09 09:25:25,078 INFO Fold 3 done!\n",
      "2023-05-09 09:25:25,079 INFO Training and predicting for fold 4\n",
      "2023-05-09 09:25:33,616 INFO Fold 4 done!\n",
      "2023-05-09 09:25:33,617 INFO Metrics: {'auc': 0.927756618236908, 'logloss': 0.27931406036069795, 'f1': 0.7102631837172906, 'accuracy': 0.8720860018764209, 'precision': 0.781039520471137, 'recall': 0.6514452530534203}\n",
      "2023-05-09 09:25:33,796 INFO No test data supplied. Only OOF predictions were generated\n"
     ]
    }
   ],
   "source": [
    "from nexora import AutoTuna\n",
    "\n",
    "payload = dict(\n",
    "    train_filename=\"./data_samples/binary_classification.csv\",\n",
    "    output=\"binary-xgb-study-2\",\n",
    "    algo='xgb',\n",
    "    test_filename=None,\n",
    "    task=None,\n",
    "    idx=None,\n",
    "    targets=[\"income\"],\n",
    "    features=None,\n",
    "    categorical_features=None,\n",
    "    use_gpu=False,\n",
    "    num_folds=5,\n",
    "    seed=42,\n",
    "    num_trials=100,\n",
    "    time_limit=360,\n",
    "    fast=False,\n",
    "    fs=1\n",
    ")\n",
    "\n",
    "# Now its time to train the model!\n",
    "atuna = AutoTuna(\n",
    "    **payload\n",
    ")\n",
    "atuna.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbc6af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
